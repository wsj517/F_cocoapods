//
//  Customer_CameraViewController.swift
//  Robot
//
//  Created by wsj on 2017/3/7.
//  Copyright © 2017年 com.qk365. All rights reserved.
//0.9.0


import UIKit
import AVFoundation
import Photos


open class Customer_CameraViewController: UIViewController,AVCaptureFileOutputRecordingDelegate {
    typealias send_url_block = (URL,Error)->()
    
    var url_block : send_url_block!
    var text:String = ""
    //视频捕获会话。它是input和output的桥梁。它协调着intput到output的数据传输
    let captureSession = AVCaptureSession.init()
    
    //音频输入设备
    let audioDevice = AVCaptureDevice.defaultDevice(withMediaType: AVMediaTypeAudio)
    
    var videoInput :AVCaptureDeviceInput!
    //将捕获到的视频输出到文件
    let fileOutput = AVCaptureMovieFileOutput.init()
    
    var camera_position:AVCaptureDevicePosition!//摄像头位置
    
    
    //开始、停止按钮
    var startButton, stopButton,chanButton : UIButton!
    //表示当时是否在录像中
    var isRecording = false
    required public init?(coder aDecoder: NSCoder) {
        fatalError("init(coder:) has not been implemented")
    }
    init(camera_position:AVCaptureDevicePosition) {
        super.init(nibName: nil, bundle: nil)
        self.camera_position = camera_position
    }
    

    
    
    override open func viewDidLoad() {
        super.viewDidLoad()
        
        let audioSession = AVAudioSession.sharedInstance()
        audioSession.requestRecordPermission { (allowed) in
            if !allowed{
//                let alertView = UIAlertView(title: "无法访问您的麦克风" , message: "请到设置 -> 隐私 -> 麦克风 ，打开访问权限", delegate: nil, cancelButtonTitle: "取消", otherButtonTitles: "好的")
//                alertView.show()
                print("无法访问您的麦克风")
            }else{
                
                //初始化录像设备
                self.initCapture();
                //创建按钮   //自定义界面
                self.setupButton()
                //启动session会话
                self.captureSession.startRunning()
            }
        }
        
        
    }
    //获取摄像头位置
    func getCameraDeviceWithPosition(position:AVCaptureDevicePosition) -> AVCaptureDevice{
        let cameras = AVCaptureDevice.devices(withMediaType:AVMediaTypeVideo)
        for camera in cameras! {
            if (camera as AnyObject).position == position {
                return camera as! AVCaptureDevice
            }
        }
        return cameras!.first as! AVCaptureDevice
    }
    //初始化录像
    func initCapture(){
        //创建AVCaptureSession对象
//        if self.captureSession.canSetSessionPreset(AVCaptureSessionPreset640x480){
//            self.captureSession.sessionPreset = AVCaptureSessionPreset640x480
//        }
        //视频输入设备
        let captureDeive = getCameraDeviceWithPosition(position: self.camera_position)
        if captureDeive.position != self.camera_position {
            print("获取后置摄像头失败")
            return
        }

        //添加一个音频设备
        _ = AVCaptureDevice.devices(withMediaType: AVMediaTypeAudio).first as!AVCaptureDevice
        //根据使用设备初始化输出设备对象audioCaptureDevice
        do {
           _ = try AVCaptureDeviceInput(device: captureDeive)
        } catch {
            print("获取输出设备失败")
            return
        }
        do {
            videoInput = try! AVCaptureDeviceInput.init(device: captureDeive)
            self.captureSession.addInput(videoInput)
        } catch {
            print("获取输出videoInput对象失败")
            return
        }
        do {
            let audioInput = try! AVCaptureDeviceInput.init(device: self.audioDevice)
            self.captureSession.addInput(audioInput);

        } catch {
            print("获取输出audioInput对象失败")
            return
        }
        //初始化输出对象，用于获得输出数据
        
        //将设备添加到会话层
        self.fileOutput.movieFragmentInterval = kCMTimeInvalid
        if let captureConnection = fileOutput.connection(withMediaType: AVMediaTypeAudio){
            if captureConnection.isVideoStabilizationSupported{
                captureConnection.preferredVideoStabilizationMode = .auto
//                captureConnection.videoOrientation = .portraitUpsideDown
            }
        }
        
        //将设备添加到会话中
        if captureSession.canAddOutput(fileOutput){
            captureSession.addOutput(fileOutput)
        }//创建视频浏览层，用于实时展示摄像头状态
        //使用AVCaptureVideoPreviewLayer可以将摄像头的拍摄的实时画面显示在ViewController上
        if let videoLayer = AVCaptureVideoPreviewLayer(session: self.captureSession) {
            videoLayer.frame = self.view.bounds
            videoLayer.videoGravity = AVLayerVideoGravityResizeAspect
            self.view.layer.addSublayer(videoLayer)
        }
        //添加设备区域改变通知
        //注意添加区域改变捕获通知必须首先设置设备允许捕获
        addNotificationToCaptureDevice(captureDevice: captureDeive)
        
    }
    //给设备添加通知
    func addNotificationToCaptureDevice(captureDevice:AVCaptureDevice){
        
        changeDeviceProperty { (captureDevice) -> Void in
            captureDevice.isSubjectAreaChangeMonitoringEnabled = true
        }
        
    }
    //改变设备属性的统一操作方法
    func changeDeviceProperty(closure :(_ captureDevice:AVCaptureDevice) -> Void) {
        let cDevice = videoInput.device
        do {
            
            try cDevice?.lockForConfiguration()
            closure(cDevice!)
            cDevice?.unlockForConfiguration()
        } catch {
            print("设置设备属性的过程中发生错误")
            
        }
        
    }
        
        
    //创建按钮
    func setupButton(){
        //创建开始按钮
        self.startButton = UIButton(frame: CGRect(x:0,y:0,width:120,height:50))
        self.startButton.backgroundColor = UIColor.red
        self.startButton.layer.masksToBounds = true
        self.startButton.setTitle("开始", for: .normal)
        self.startButton.layer.cornerRadius = 20.0
        self.startButton.layer.position = CGPoint(x:self.view.bounds.width/2 - 70,
                                                  y:self.view.bounds.height-50)
        self.startButton.addTarget(self, action: #selector(onClickStartButton(_:)),
                                   for: .touchUpInside)
        
        //创建停止按钮
        self.stopButton = UIButton(frame: CGRect(x:0,y:0,width:120,height:50))
        self.stopButton.backgroundColor = UIColor.gray
        self.stopButton.layer.masksToBounds = true
        self.stopButton.setTitle("停止", for: .normal)
        self.stopButton.layer.cornerRadius = 20.0
        
        self.stopButton.layer.position = CGPoint(x: self.view.bounds.width/2 + 70,
                                                 y:self.view.bounds.height-50)
        self.stopButton.addTarget(self, action: #selector(onClickStopButton(_:)),
                                  for: .touchUpInside)
        
        //切换摄像头
        self.chanButton = UIButton(frame:CGRect(x:0,y:0,width:120,height:50))
        self.chanButton.backgroundColor = .gray
        self.chanButton.layer.masksToBounds = true
        self.chanButton.setTitle("切换", for: .normal)
        self.chanButton.layer.cornerRadius = 20.0
        self.chanButton.layer.position = CGPoint(x:self.view.bounds.width/2 - 70,y:50)
        self.chanButton.addTarget(self, action: #selector(changeCamrel),
                                  for: .touchUpInside)

        //添加按钮到视图上
        self.view.addSubview(self.startButton)
        self.view.addSubview(self.stopButton)
        self.view.addSubview(self.chanButton)
    }
    //切换摄像头
    func changeCamrel(){
        //获得设备
        let currentDevice = videoInput.device
        //获得设备位置
        let currentPosition = currentDevice?.position
        //改变设备发出通知
        NotificationCenter.default.removeObserver(self, name: NSNotification.Name.AVCaptureDeviceSubjectAreaDidChange, object: currentDevice)
        var toChangePosition = AVCaptureDevicePosition.front
        if currentPosition == AVCaptureDevicePosition.unspecified || currentPosition == AVCaptureDevicePosition.front {
            
            toChangePosition = AVCaptureDevicePosition.back
        }
        let toChangeDevice = getCameraDeviceWithPosition(position: toChangePosition)
        addNotificationToCaptureDevice(captureDevice: toChangeDevice)
        //获得要调整的输入对象
        var toChangeDeviceInput :AVCaptureDeviceInput!
        do {
            toChangeDeviceInput = try AVCaptureDeviceInput(device: toChangeDevice)
        } catch {}
        //改变配置之前一定要先开启配置，配置完成后提交配置改变
        captureSession.beginConfiguration()
        //移除原有输入对象
        captureSession.removeInput(videoInput)
        //添加新的输入对象
        if captureSession.canAddInput(toChangeDeviceInput){
            captureSession.addInput(toChangeDeviceInput)
            videoInput = toChangeDeviceInput
        }
        //提交会话配置
        captureSession.commitConfiguration()
        
    }
    //开始按钮点击，开始录像
    func onClickStartButton(_ sender: UIButton){
        self.chanButton.isHidden = true//隐藏切换摄像头
//        DispatchQueue.main.async {
//            self.videoRecognition()//录音开始时初始化语音识别系统
//        }

        
        
        if !self.isRecording {
            //设置录像的保存地址（在Documents目录下，名为temp.mp4）
            let paths = NSSearchPathForDirectoriesInDomains(.documentDirectory,
                                                            .userDomainMask, true)
            let documentsDirectory = paths[0] as String
            let filePath = "\(documentsDirectory)/temp.mp4"
            let fileURL = URL(fileURLWithPath: filePath)
            //   视频编码输出
            fileOutput.startRecording(toOutputFileURL: fileURL, recordingDelegate: self)
            
            //记录状态：录像中...
            self.isRecording = true
            //开始、结束按钮颜色改变
            self.changeButtonColor(target: self.startButton, color: .gray)
            self.changeButtonColor(target: self.stopButton, color: .red)
        }
    }
    
    //停止按钮点击，停止录像
    func onClickStopButton(_ sender: UIButton){
        self.chanButton.isHidden = false//显示切换摄像头

        if self.isRecording {
            //停止视频编码输出
            fileOutput.stopRecording()
            
            //记录状态：录像结束
            self.isRecording = false
            //开始、结束按钮颜色改变
            self.changeButtonColor(target: self.startButton, color: .red)
            self.changeButtonColor(target: self.stopButton, color: .gray)
            
        }
    }
    
    //修改按钮的颜色
    func changeButtonColor(target: UIButton, color: UIColor){
        target.backgroundColor = color
    }
    
    //录像开始的代理方法
    public func capture(_ captureOutput: AVCaptureFileOutput!,
                 didStartRecordingToOutputFileAt fileURL: URL!,
                 fromConnections connections: [Any]!) {
    }
    
    //录像结束的代理方法
    public func capture(_ captureOutput: AVCaptureFileOutput!,
                 didFinishRecordingToOutputFileAt outputFileURL: URL!,
                 fromConnections connections: [Any]!, error: Error!) {
//        let message = "i love u"
//        //将录制好的录像保存到照片库中
//        PHPhotoLibrary.shared().performChanges({
//            PHAssetChangeRequest.creationRequestForAssetFromVideo(atFileURL: outputFileURL)
//        }, completionHandler: { (isSuccess: Bool, error: Error?) in
//            if isSuccess {
//                message = "保存成功!"
//            } else{
//                message = "保存失败：\(error!.localizedDescription)"
//            }
//            
//            DispatchQueue.main.async {
//                //弹出提示框
//                let alertController = UIAlertController(title: message, message: nil,
//                                                        preferredStyle: .alert)
//                let cancelAction = UIAlertAction(title: "确定", style: .cancel, handler: nil)
//                alertController.addAction(cancelAction)
//                self.present(alertController, animated: true, completion: nil)
//            }
//        })
        //把语音加到视频上
//        VoiceToTxtManager.shared().mixVideo(withText: outputFileURL, text: self.text) { (outPath) in
//            
//            print("---------------------outPath:\(outPath)")
//            if (self.url_block) != nil{
//                self.url_block(outPath!)
//            }
//            
//        }
            if (self.url_block) != nil{
                self.url_block(outputFileURL!,error)
            }
      
        self.dismiss(animated: true, completion: nil)
//        VoiceToTxtManager.shared().finishRecord(nil)
    }
    
    //初始化语音识别
//    private func videoRecognition() {
//        
//        var resutlString = ""
//        
//        VoiceToTxtManager.shared().initializedVoiceRecogniton({ () -> UIView? in
//            
//            return UIApplication.shared.keyWindow
//            
//        }, continusManualResult: { (continusManualResult) in
//            
//            resutlString = continusManualResult!
//            
//        }, manualResult: { (manualResult, isSuccess) in
//            
//            if isSuccess {
//                
//                if resutlString == "" {
//                    
//                    resutlString = manualResult!
//                } else {
//                    
//                    resutlString = resutlString.appending(manualResult!)
//                }
//                
//                self.text = resutlString
//                
//                print("recognition success !!!:%@",self.text)
//                
//            } else {
//                
//                //语音识别未成功
//            }
//            
//        }) {
//            //语音识别中
//        }
//    }

}
